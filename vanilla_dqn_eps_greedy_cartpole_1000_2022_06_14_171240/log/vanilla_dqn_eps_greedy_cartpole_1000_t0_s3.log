[2022-06-14 17:12:43,236 PID:18392 INFO openai.py __init__] OpenAIEnv:
- env_spec = {'max_frame': 10000, 'max_t': 10, 'name': 'CartPole-v0'}
- eval_frequency = 1000
- log_frequency = 1000
- frame_op = None
- frame_op_len = None
- image_downsize = (84, 84)
- normalize_state = False
- reward_scale = None
- num_envs = 1
- name = CartPole-v0
- max_t = 10
- max_frame = 10000
- to_render = False
- is_venv = False
- clock_speed = 1
- clock = <slm_lab.env.base.Clock object at 0x7f72f4eb0ef0>
- done = False
- total_reward = nan
- u_env = <TrackReward<TimeLimit<CartPoleEnv<CartPole-v0>>>>
- observation_space = Box(4,)
- action_space = Discrete(2)
- observable_dim = {'state': 4}
- action_dim = 2
- is_discrete = True
[2022-06-14 17:12:48,111 PID:18392 INFO base.py end_init_nets] Initialized algorithm models for lab_mode: train
[2022-06-14 17:12:48,126 PID:18392 INFO base.py __init__] VanillaDQN:
- agent = <slm_lab.agent.Agent object at 0x7f72e9db8cf8>
- action_pdtype = Argmax
- action_policy = <function epsilon_greedy at 0x7f723a726378>
- explore_var_spec = {'end_step': 4000,
 'end_val': 0.05,
 'name': 'linear_decay',
 'start_step': 0,
 'start_val': 1.0}
- training_start_step = 32
- gamma = 0.99
- training_batch_iter = 8
- training_iter = 4
- training_frequency = 4
- to_train = 0
- explore_var_scheduler = <slm_lab.agent.algorithm.policy_util.VarScheduler object at 0x7f722bca20b8>
- net = MLPNet(
  (model): Sequential(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): SELU()
  )
  (model_tail): Sequential(
    (0): Linear(in_features=64, out_features=2, bias=True)
  )
  (loss_fn): MSELoss()
)
- net_names = ['net']
- optim = Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.01
    lr: 0.01
    weight_decay: 0
)
- lr_scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f722bca2400>
- global_net = None
[2022-06-14 17:12:48,129 PID:18392 INFO __init__.py __init__] Agent:
- spec = {'cuda_offset': 0,
 'distributed': False,
 'eval_frequency': 1000,
 'experiment': 0,
 'experiment_ts': '2022_06_14_171240',
 'git_sha': '9102ff923d7a3e9c579edc18c6547cce94a7b77a',
 'graph_prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/graph/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'info_prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/info/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'log_frequency': 1000,
 'log_prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/log/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'max_session': 4,
 'max_trial': 1,
 'model_prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/model/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'random_seed': 1655197363,
 'resume': False,
 'rigorous_eval': 0,
 'session': 3,
 'trial': 0}
- agent_spec = {'algorithm': {'action_pdtype': 'Argmax',
               'action_policy': 'epsilon_greedy',
               'explore_var_spec': {'end_step': 4000,
                                    'end_val': 0.05,
                                    'name': 'linear_decay',
                                    'start_step': 0,
                                    'start_val': 1.0},
               'gamma': 0.99,
               'name': 'VanillaDQN',
               'training_batch_iter': 8,
               'training_frequency': 4,
               'training_iter': 4,
               'training_start_step': 32},
 'memory': {'batch_size': 32,
            'max_size': 10000,
            'name': 'Replay',
            'use_cer': False},
 'name': 'VanillaDQN',
 'net': {'clip_grad_val': 0.5,
         'cuda_id': 0,
         'gpu': True,
         'hid_layers': [64],
         'hid_layers_activation': 'selu',
         'loss_spec': {'name': 'MSELoss'},
         'lr_scheduler_spec': {'frame': 10000, 'name': 'LinearToZero'},
         'optim_spec': {'lr': 0.01, 'name': 'Adam'},
         'type': 'MLPNet'}}
- name = VanillaDQN
- body = body: {
  "agent": "<slm_lab.agent.Agent object at 0x7f72e9db8cf8>",
  "env": "<slm_lab.env.openai.OpenAIEnv object at 0x7f723a8670f0>",
  "a": 0,
  "e": 0,
  "b": 0,
  "aeb": "(0, 0, 0)",
  "explore_var": 1.0,
  "entropy_coef": NaN,
  "loss": NaN,
  "mean_entropy": NaN,
  "mean_grad_norm": NaN,
  "best_total_reward_ma": -Infinity,
  "total_reward_ma": NaN,
  "train_df": "Empty DataFrame\nColumns: [epi, t, wall_t, opt_step, frame, fps, total_reward, total_reward_ma, loss, lr, explore_var, entropy_coef, entropy, grad_norm]\nIndex: []",
  "eval_df": "Empty DataFrame\nColumns: [epi, t, wall_t, opt_step, frame, fps, total_reward, total_reward_ma, loss, lr, explore_var, entropy_coef, entropy, grad_norm]\nIndex: []",
  "observation_space": "Box(4,)",
  "action_space": "Discrete(2)",
  "observable_dim": {
    "state": 4
  },
  "state_dim": 4,
  "action_dim": 2,
  "is_discrete": true,
  "action_type": "discrete",
  "action_pdtype": "Argmax",
  "ActionPD": "<class 'slm_lab.lib.distribution.Argmax'>",
  "memory": "<slm_lab.agent.memory.replay.Replay object at 0x7f722bce1e80>"
}
- algorithm = <slm_lab.agent.algorithm.dqn.VanillaDQN object at 0x7f722bca2048>
[2022-06-14 17:12:48,130 PID:18392 INFO logger.py info] Session:
- spec = {'cuda_offset': 0,
 'distributed': False,
 'eval_frequency': 1000,
 'experiment': 0,
 'experiment_ts': '2022_06_14_171240',
 'git_sha': '9102ff923d7a3e9c579edc18c6547cce94a7b77a',
 'graph_prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/graph/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'info_prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/info/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'log_frequency': 1000,
 'log_prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/log/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'max_session': 4,
 'max_trial': 1,
 'model_prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/model/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'prepath': 'data/vanilla_dqn_eps_greedy_cartpole_1000_2022_06_14_171240/vanilla_dqn_eps_greedy_cartpole_1000_t0_s3',
 'random_seed': 1655197363,
 'resume': False,
 'rigorous_eval': 0,
 'session': 3,
 'trial': 0}
- index = 3
- agent = <slm_lab.agent.Agent object at 0x7f72e9db8cf8>
- env = <slm_lab.env.openai.OpenAIEnv object at 0x7f723a8670f0>
- eval_env = <slm_lab.env.openai.OpenAIEnv object at 0x7f723a8670f0>
[2022-06-14 17:12:48,130 PID:18392 INFO logger.py info] Running RL loop for trial 0 session 3
[2022-06-14 17:12:48,152 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 0  t: 0  wall_t: 0  opt_step: 0  frame: 0  fps: 0  total_reward: nan  total_reward_ma: nan  loss: nan  lr: 0.01  explore_var: 1  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:14:35,531 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 91  t: 2  wall_t: 112  opt_step: 38720  frame: 1000  fps: 8.92857  total_reward: 8  total_reward_ma: 8  loss: 115.862  lr: 0.009003  explore_var: 0.7625  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:16:28,552 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 182  t: 4  wall_t: 225  opt_step: 78720  frame: 2000  fps: 8.88889  total_reward: 10  total_reward_ma: 9  loss: 138.812  lr: 0.008003  explore_var: 0.525  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:16:28,578 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9  strength: -12.86  max_strength: -11.86  final_strength: -11.86  sample_efficiency: 0.00076944  training_efficiency: 1.97751e-05  stability: 1
[2022-06-14 17:18:21,446 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 273  t: 11  wall_t: 338  opt_step: 118720  frame: 3000  fps: 8.87574  total_reward: 11  total_reward_ma: 9.66667  loss: 54.783  lr: 0.007003  explore_var: 0.2875  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:18:21,466 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.66667  strength: -12.1933  max_strength: -10.86  final_strength: -10.86  sample_efficiency: 0.000639967  training_efficiency: 1.64049e-05  stability: 1
[2022-06-14 17:18:21,472 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 273  t: 11  wall_t: 338  opt_step: 118720  frame: 3000  fps: 8.87574  total_reward: 11  total_reward_ma: 9.66667  loss: 54.783  lr: 0.007003  explore_var: 0.2875  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:18:21,490 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.66667  strength: -12.1933  max_strength: -10.86  final_strength: -10.86  sample_efficiency: 0.000639967  training_efficiency: 1.64049e-05  stability: 1
[2022-06-14 17:20:14,890 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 365  t: 2  wall_t: 451  opt_step: 158720  frame: 4000  fps: 8.86918  total_reward: 8  total_reward_ma: 9.25  loss: 31.0341  lr: 0.006003  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:20:14,908 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.25  strength: -12.61  max_strength: -10.86  final_strength: -13.86  sample_efficiency: 0.000532811  training_efficiency: 1.36284e-05  stability: 0.917988
[2022-06-14 17:22:06,379 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 456  t: 2  wall_t: 563  opt_step: 198720  frame: 5000  fps: 8.88099  total_reward: 10  total_reward_ma: 9.4  loss: 18.4309  lr: 0.005003  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:22:06,400 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.4  strength: -12.46  max_strength: -10.86  final_strength: -11.86  sample_efficiency: 0.000469454  training_efficiency: 1.19919e-05  stability: 0.940523
[2022-06-14 17:24:00,765 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 547  t: 1  wall_t: 677  opt_step: 238720  frame: 6000  fps: 8.86263  total_reward: 10  total_reward_ma: 9.5  loss: 20.8457  lr: 0.004003  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:24:00,784 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.5  strength: -12.36  max_strength: -10.86  final_strength: -11.86  sample_efficiency: 0.000421031  training_efficiency: 1.0744e-05  stability: 0.951846
[2022-06-14 17:25:51,654 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 637  t: 11  wall_t: 788  opt_step: 278720  frame: 7000  fps: 8.88325  total_reward: 10  total_reward_ma: 9.57143  loss: 16.2856  lr: 0.003003  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:25:51,673 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.57143  strength: -12.2886  max_strength: -10.86  final_strength: -11.86  sample_efficiency: 0.000382678  training_efficiency: 9.75738e-06  stability: 0.959547
[2022-06-14 17:25:51,679 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 637  t: 11  wall_t: 788  opt_step: 278720  frame: 7000  fps: 8.88325  total_reward: 10  total_reward_ma: 9.57143  loss: 16.2856  lr: 0.003003  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:25:51,696 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.57143  strength: -12.2886  max_strength: -10.86  final_strength: -11.86  sample_efficiency: 0.000382678  training_efficiency: 9.75738e-06  stability: 0.959547
[2022-06-14 17:27:43,540 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 728  t: 10  wall_t: 900  opt_step: 318720  frame: 8000  fps: 8.88889  total_reward: 10  total_reward_ma: 9.625  loss: 10.8176  lr: 0.002003  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:27:43,559 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.625  strength: -12.235  max_strength: -10.86  final_strength: -11.86  sample_efficiency: 0.000351455  training_efficiency: 8.95526e-06  stability: 0.965124
[2022-06-14 17:29:34,762 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 819  t: 9  wall_t: 1011  opt_step: 358720  frame: 9000  fps: 8.90208  total_reward: 10  total_reward_ma: 9.66667  loss: 20.6688  lr: 0.001003  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:29:34,781 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.66667  strength: -12.1933  max_strength: -10.86  final_strength: -11.86  sample_efficiency: 0.00032548  training_efficiency: 8.28871e-06  stability: 0.96935
[2022-06-14 17:31:15,032 PID:18392 INFO __init__.py log_summary] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df] epi: 910  t: 8  wall_t: 1111  opt_step: 398720  frame: 10000  fps: 9.0009  total_reward: 10  total_reward_ma: 9.7  loss: 18.6574  lr: 3e-06  explore_var: 0.05  entropy_coef: nan  entropy: nan  grad_norm: nan
[2022-06-14 17:31:15,051 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [train_df metrics] final_return_ma: 9.7  strength: -12.16  max_strength: -10.86  final_strength: -11.86  sample_efficiency: 0.000303489  training_efficiency: 7.7249e-06  stability: 0.972663
[2022-06-14 17:31:17,902 PID:18392 INFO __init__.py log_metrics] Trial 0 session 3 vanilla_dqn_eps_greedy_cartpole_1000_t0_s3 [eval_df metrics] final_return_ma: 9.7  strength: -12.16  max_strength: -10.86  final_strength: -11.86  sample_efficiency: 0.000303489  training_efficiency: 7.7249e-06  stability: 0.972663
[2022-06-14 17:31:17,907 PID:18392 INFO logger.py info] Session 3 done
